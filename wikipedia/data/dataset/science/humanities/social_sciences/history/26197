Radiocarbon dating (also referred to as carbon dating or carbon-14 dating) is a method for determining the age of an object containing organic material by using the properties of radiocarbon (14C), a radioactive isotope of carbon.
The method was developed by Willard Libby in the late 1940s and soon became a standard tool for archaeologists. Libby received the Nobel Prize in Chemistry for his work in 1960. The radiocarbon dating method is based on the fact that radiocarbon is constantly being created in the atmosphere by the interaction of cosmic rays with atmospheric nitrogen. The resulting radiocarbon combines with atmospheric oxygen to form radioactive carbon dioxide, which is incorporated into plants by photosynthesis; animals then acquire 14C by eating the plants. When the animal or plant dies, it stops exchanging carbon with its environment, and from that point onwards the amount of 14C it contains begins to decrease as the 14C undergoes radioactive decay. Measuring the amount of 14C in a sample from a dead plant or animal such as a piece of wood or a fragment of bone provides information that can be used to calculate when the animal or plant died. The older a sample is, the less 14C there is to be detected, and because the half-life of 14C (the period of time after which half of a given sample will have decayed) is about 5,730 years, the oldest dates that can be reliably measured by this process date to around 50,000 years ago, although special preparation methods occasionally permit accurate analysis of older samples.
The idea behind radiocarbon dating is straightforward, but years of work were required to develop the technique to the point where accurate dates could be obtained. Research has been ongoing since the 1960s to determine what the proportion of 14C in the atmosphere has been over the past fifty thousand years. The resulting data, in the form of a calibration curve, is now used to convert a given measurement of radiocarbon in a sample into an estimate of the sample's calendar age. Other corrections must be made to account for the proportion of 14C in different types of organisms (fractionation), and the varying levels of 14C throughout the biosphere (reservoir effects). Additional complications come from the burning of fossil fuels such as coal and oil, and from the above-ground nuclear tests done in the 1950s and 1960s. Because the time it takes to convert biological materials to fossil fuels is substantially longer than the time it takes for its 14C to decay below detectable levels, fossil fuels contain almost no 14C, and as a result there was a noticeable drop in the proportion of 14C in the atmosphere beginning in the late 19th century. Conversely, nuclear testing increased the amount of 14C in the atmosphere, which attained a maximum in 1963 of almost twice what it had been before the testing began.
Measurement of radiocarbon was originally done by beta-counting devices, which counted the amount of beta radiation emitted by decaying 14C atoms in a sample. More recently, accelerator mass spectrometry has become the method of choice; it counts all the 14C atoms in the sample and not just the few that happen to decay during the measurements; it can therefore be used with much smaller samples (as small as individual plant seeds), and gives results much more quickly. The development of radiocarbon dating has had a profound impact on archaeology. In addition to permitting more accurate dating within archaeological sites than previous methods, it allows comparison of dates of events across great distances. Histories of archaeology often refer to its impact as the "radiocarbon revolution". Radiocarbon dating has allowed key transitions in prehistory to be dated, such as the end of the last ice age, and the beginning of the Neolithic and Bronze Age in different regions.
