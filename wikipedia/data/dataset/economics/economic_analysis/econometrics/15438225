In statistics and econometrics, a distributed lag model is a model for time series data in which a regression equation is used to predict current values of a dependent variable based on both the current values of an explanatory variable and the lagged (past period) values of this explanatory variable.
The starting point for a distributed lag model is an assumed structure of the form

  
    
      
        
          y
          
            t
          
        
        =
        a
        +
        
          w
          
            0
          
        
        
          x
          
            t
          
        
        +
        
          w
          
            1
          
        
        
          x
          
            t
            −
            1
          
        
        +
        
          w
          
            2
          
        
        
          x
          
            t
            −
            2
          
        
        +
        .
        .
        .
        +
        
          error term
        
      
    
    {\displaystyle y_{t}=a+w_{0}x_{t}+w_{1}x_{t-1}+w_{2}x_{t-2}+...+{\text{error term}}}
  
or the form

  
    
      
        
          y
          
            t
          
        
        =
        a
        +
        
          w
          
            0
          
        
        
          x
          
            t
          
        
        +
        
          w
          
            1
          
        
        
          x
          
            t
            −
            1
          
        
        +
        
          w
          
            2
          
        
        
          x
          
            t
            −
            2
          
        
        +
        .
        .
        .
        +
        
          w
          
            n
          
        
        
          x
          
            t
            −
            n
          
        
        +
        
          error term
        
        ,
      
    
    {\displaystyle y_{t}=a+w_{0}x_{t}+w_{1}x_{t-1}+w_{2}x_{t-2}+...+w_{n}x_{t-n}+{\text{error term}},}
  
where yt is the value at time period t of the dependent variable y, a is the intercept term to be estimated, and wi is called the lag weight (also to be estimated) placed on the value i periods previously of the explanatory variable x. In the first equation, the dependent variable is assumed to be affected by values of the independent variable arbitrarily far in the past, so the number of lag weights is infinite and the model is called an infinite distributed lag model. In the alternative, second, equation, there are only a finite number of lag weights, indicating an assumption that there is a maximum lag beyond which values of the independent variable do not affect the dependent variable; a model based on this assumption is called a finite distributed lag model.
In an infinite distributed lag model, an infinite number of lag weights need to be estimated; clearly this can be done only if some structure is assumed for the relation between the various lag weights, with the entire infinitude of them expressible in terms of a finite number of assumed underlying parameters. In a finite distributed lag model, the parameters could be directly estimated by ordinary least squares (assuming the number of data points sufficiently exceeds the number of lag weights); nevertheless, such estimation may give very imprecise results due to extreme multicollinearity among the various lagged values of the independent variable, so again it may be necessary to assume some structure for the relation between the various lag weights.
The concept of distributed lag models easily generalizes to the context of more than one right-side explanatory variable.


