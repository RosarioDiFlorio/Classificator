In statistics, the Johansen test, named after Søren Johansen, is a procedure for testing cointegration of several, say k, I(1) time series. For the presence of I(2) variables see Ch. 9 of his 1995 textbook. This test permits more than one cointegrating relationship so is more generally applicable than the Engle–Granger test which is based on the Dickey–Fuller (or the augmented) test for unit roots in the residuals from a single (estimated) cointegrating relationship.
There are two types of Johansen test, either with trace or with eigenvalue, and the inferences might be a little bit different. The null hypothesis for the trace test is that the number of cointegration vectors is r=r*<k, vs. the alternative that r=k. Testing proceeds sequentially for r*=1,2,etc. and the first non-rejection of the null is taken as an estimate of r. The null hypothesis for the "maximum eigenvalue" test is as for the trace test but the alternative is r=r*+1 and, again, testing proceeds sequentially for r*=1,2,etc., with the first non-rejection used as an estimator for r.
Just like a unit root test, there can be a constant term, a trend term, both, or neither in the model. For a general VAR(p) model:

  
    
      
        
          X
          
            t
          
        
        =
        μ
        +
        Φ
        
          D
          
            t
          
        
        +
        
          Π
          
            p
          
        
        
          X
          
            t
            −
            p
          
        
        +
        ⋯
        +
        
          Π
          
            1
          
        
        
          X
          
            t
            −
            1
          
        
        +
        
          e
          
            t
          
        
        ,
        
        t
        =
        1
        ,
        …
        ,
        T
      
    
    {\displaystyle X_{t}=\mu +\Phi D_{t}+\Pi _{p}X_{t-p}+\cdots +\Pi _{1}X_{t-1}+e_{t},\quad t=1,\dots ,T}
  
There are two possible specifications for error correction: that is, two VECM (vector error correction models):
1. The longrun VECM:

  
    
      
        Δ
        
          X
          
            t
          
        
        =
        μ
        +
        Φ
        
          D
          
            t
          
        
        +
        Π
        
          X
          
            t
            −
            p
          
        
        +
        
          Γ
          
            p
            −
            1
          
        
        Δ
        
          X
          
            t
            −
            p
            +
            1
          
        
        +
        ⋯
        +
        
          Γ
          
            1
          
        
        Δ
        
          X
          
            t
            −
            1
          
        
        +
        
          ε
          
            t
          
        
        ,
        
        t
        =
        1
        ,
        …
        ,
        T
      
    
    {\displaystyle \Delta X_{t}=\mu +\Phi D_{t}+\Pi X_{t-p}+\Gamma _{p-1}\Delta X_{t-p+1}+\cdots +\Gamma _{1}\Delta X_{t-1}+\varepsilon _{t},\quad t=1,\dots ,T}
  

where

  
    
      
        
          Γ
          
            i
          
        
        =
        
          Π
          
            1
          
        
        +
        ⋯
        +
        
          Π
          
            i
          
        
        −
        I
        ,
        
        i
        =
        1
        ,
        …
        ,
        p
        −
        1.
        
      
    
    {\displaystyle \Gamma _{i}=\Pi _{1}+\cdots +\Pi _{i}-I,\quad i=1,\dots ,p-1.\,}
  

2. The transitory VECM:

  
    
      
        Δ
        
          X
          
            t
          
        
        =
        μ
        +
        Φ
        
          D
          
            t
          
        
        −
        
          Γ
          
            p
            −
            1
          
        
        Δ
        
          X
          
            t
            −
            p
            +
            1
          
        
        −
        ⋯
        −
        
          Γ
          
            1
          
        
        Δ
        
          X
          
            t
            −
            1
          
        
        +
        Π
        
          X
          
            t
            −
            1
          
        
        +
        
          ε
          
            t
          
        
        ,
        
        t
        =
        1
        ,
        ⋯
        ,
        T
      
    
    {\displaystyle \Delta X_{t}=\mu +\Phi D_{t}-\Gamma _{p-1}\Delta X_{t-p+1}-\cdots -\Gamma _{1}\Delta X_{t-1}+\Pi X_{t-1}+\varepsilon _{t},\quad t=1,\cdots ,T}
  

where

  
    
      
        
          Γ
          
            i
          
        
        =
        
          (
          
            Π
            
              i
              +
              1
            
          
          +
          ⋯
          +
          
            Π
            
              p
            
          
          )
        
        ,
        
        i
        =
        1
        ,
        …
        ,
        p
        −
        1.
        
      
    
    {\displaystyle \Gamma _{i}=\left(\Pi _{i+1}+\cdots +\Pi _{p}\right),\quad i=1,\dots ,p-1.\,}
  

Be aware that the two are the same. In both VECM (Vector Error Correction Model),

  
    
      
        Π
        =
        
          Π
          
            1
          
        
        +
        ⋯
        +
        
          Π
          
            p
          
        
        −
        I
        .
        
      
    
    {\displaystyle \Pi =\Pi _{1}+\cdots +\Pi _{p}-I.\,}
  
Inferences are drawn on Π, and they will be the same, so is the explanatory power.
