In statistical decision theory, where we are faced with the problem of estimating a deterministic parameter (vector) 
  
    
      
        θ
        ∈
        Θ
      
    
    {\displaystyle \theta \in \Theta }
   from observations 
  
    
      
        x
        ∈
        
          
            X
          
        
        ,
      
    
    {\displaystyle x\in {\mathcal {X}},}
   an estimator (estimation rule) 
  
    
      
        
          δ
          
            M
          
        
        
        
      
    
    {\displaystyle \delta ^{M}\,\!}
   is called minimax if its maximal risk is minimal among all estimators of 
  
    
      
        θ
        
        
      
    
    {\displaystyle \theta \,\!}
  . In a sense this means that 
  
    
      
        
          δ
          
            M
          
        
        
        
      
    
    {\displaystyle \delta ^{M}\,\!}
   is an estimator which performs best in the worst possible case allowed in the problem.
